{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport os\nimport glob\nimport cv2\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport pickle\nfrom keras.utils import to_categorical\n\nfrom keras import backend as K\nimport keras\nfrom keras.layers import *\nfrom keras.callbacks import *\nfrom keras.models import *\nfrom keras.losses import *\nfrom keras.optimizers import *","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# FIG_WIDTH=20 # Width of figure\n# ROW_HEIGHT=3 # Height of each row when showing a figure which consists of multiple rows\nRESIZE_DIM=28 # The images will be resized to 28x28 pixels","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir=os.path.join('..','input/numta')\npaths_train_a=glob.glob(os.path.join(data_dir,'training-a','*.png'))\npaths_train_b=glob.glob(os.path.join(data_dir,'training-b','*.png'))\npaths_train_e=glob.glob(os.path.join(data_dir,'training-e','*.png'))\npaths_train_c=glob.glob(os.path.join(data_dir,'training-c','*.png'))\npaths_train_d=glob.glob(os.path.join(data_dir,'training-d','*.png'))\npaths_train_all=paths_train_a+paths_train_b+paths_train_c+paths_train_d+paths_train_e\n\npaths_test_a=glob.glob(os.path.join(data_dir,'testing-a','*.png'))\npaths_test_b=glob.glob(os.path.join(data_dir,'testing-b','*.png'))\npaths_test_e=glob.glob(os.path.join(data_dir,'testing-e','*.png'))\npaths_test_c=glob.glob(os.path.join(data_dir,'testing-c','*.png'))\npaths_test_d=glob.glob(os.path.join(data_dir,'testing-d','*.png'))\npaths_test_f=glob.glob(os.path.join(data_dir,'testing-f','*.png'))+glob.glob(os.path.join(data_dir,'testing-f','*.JPG'))\npaths_test_auga=glob.glob(os.path.join(data_dir,'testing-auga','*.png'))\npaths_test_augc=glob.glob(os.path.join(data_dir,'testing-augc','*.png'))\npaths_test_all=paths_test_a+paths_test_b+paths_test_c+paths_test_d+paths_test_e+paths_test_f+paths_test_auga+paths_test_augc\n\npath_label_train_a=os.path.join(data_dir,'training-a.csv')\npath_label_train_b=os.path.join(data_dir,'training-b.csv')\npath_label_train_e=os.path.join(data_dir,'training-e.csv')\npath_label_train_c=os.path.join(data_dir,'training-c.csv')\npath_label_train_d=os.path.join(data_dir,'training-d.csv')","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_key(path):\n    # seperates the key of an image from the filepath\n    key=path.split(sep=os.sep)[-1]\n    return key\n\ndef get_data(paths_img,path_label=None,resize_dim=None):\n    '''reads images from the filepaths, resizes them (if given), and returns them in a numpy array\n    Args:\n        paths_img: image filepaths\n        path_label: pass image label filepaths while processing training data, defaults to None while processing testing data\n        resize_dim: if given, the image is resized to resize_dim x resize_dim (optional)\n    Returns:\n        X: group of images\n        y: categorical true labels\n    '''\n    X=[] # initialize empty list for resized images\n    for i,path in enumerate(paths_img):\n        img=cv2.imread(path,cv2.IMREAD_GRAYSCALE) # images loaded in color (BGR)\n#         img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        if resize_dim is not None:\n            img=cv2.resize(img,(resize_dim,resize_dim),interpolation=cv2.INTER_AREA) # resize image to 28x28\n#         X.append(np.expand_dims(img,axis=2)) # expand image to 28x28x1 and append to the list.\n        X.append(img) # expand image to 28x28x1 and append to the list\n        # display progress\n        if i==len(paths_img)-1:\n            end='\\n'\n        else: end='\\r'\n        print('processed {}/{}'.format(i+1,len(paths_img)),end=end)\n        \n    X=np.array(X) # tranform list to numpy array\n    if  path_label is None:\n        return X\n    else:\n        df = pd.read_csv(path_label) # read labels\n        df=df.set_index('filename') \n        y_label=[df.loc[get_key(path)]['digit'] for path in  paths_img] # get the labels corresponding to the images\n        y=to_categorical(y_label,10) # transfrom integer value to categorical variable\n        return X, y\n\ndef imshow_group(X,y=None,y_pred=None,n_per_row=10):\n    '''helper function to visualize a group of images along with their categorical true labels (y) and prediction probabilities.\n    Args:\n        X: images\n        y: categorical true labels\n        y_pred: predicted class probabilities\n        n_per_row: number of images per row to be plotted\n    '''\n    n_sample=len(X)\n    img_dim=X.shape[1]\n    j=np.ceil(n_sample/n_per_row)\n    fig=plt.figure(figsize=(FIG_WIDTH,ROW_HEIGHT*j))\n    for i,img in enumerate(X):\n        plt.subplot(j,n_per_row,i+1)\n        plt.imshow(img)\n        if y is not None:\n                plt.title('true label: {}'.format(np.argmax(y[i])))\n        if y_pred is not None:\n            top_n=3 # top 3 predictions with highest probabilities\n            ind_sorted=np.argsort(y_pred[i])[::-1]\n            h=img_dim+4\n            for k in range(top_n):\n                string='pred: {} ({:.0f}%)\\n'.format(ind_sorted[k],y_pred[i,ind_sorted[k]]*100)\n                plt.text(img_dim/2, h, string, horizontalalignment='center',verticalalignment='center')\n                h+=4\n        plt.axis('off')\n    plt.show()\ndef create_submission(predictions,keys,path):\n    result = pd.DataFrame(\n        predictions,\n        columns=['label'],\n        index=keys\n        )\n    result.index.name='key'\n    result.to_csv(path, index=True)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_a,y_train_a=get_data(paths_train_a,path_label_train_a,resize_dim=RESIZE_DIM)\nX_train_b,y_train_b=get_data(paths_train_b,path_label_train_b,resize_dim=RESIZE_DIM)\n# X_train_c,y_train_c=get_data(paths_train_c,path_label_train_c,resize_dim=RESIZE_DIM)\n# X_train_d,y_train_d=get_data(paths_train_d,path_label_train_d,resize_dim=RESIZE_DIM)\n# X_train_e,y_train_e=get_data(paths_train_e,path_label_train_e,resize_dim=RESIZE_DIM)","execution_count":9,"outputs":[{"output_type":"stream","text":"processed 19702/19702\nprocessed 359/359\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_all=np.concatenate((X_train_a,X_train_b),axis=0)\ny_train_all=np.concatenate((y_train_a,y_train_b),axis=0)\nX_train_all.shape, y_train_all.shape","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"((20061, 28, 28), (20061, 10))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_test_a=get_data(paths_test_a,resize_dim=RESIZE_DIM)\n# X_test_b=get_data(paths_test_b,resize_dim=RESIZE_DIM)\n# X_test_c=get_data(paths_test_c,resize_dim=RESIZE_DIM)\n# X_test_d=get_data(paths_test_d,resize_dim=RESIZE_DIM)\n# X_test_e=get_data(paths_test_e,resize_dim=RESIZE_DIM)\n# X_test_f=get_data(paths_test_f,resize_dim=RESIZE_DIM)\n# X_test_auga=get_data(paths_test_auga,resize_dim=RESIZE_DIM)\n# X_test_augc=get_data(paths_test_augc,resize_dim=RESIZE_DIM)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"indices=list(range(len(X_train_all)))\nnp.random.seed(42)\nnp.random.shuffle(indices)\n\nind=int(len(indices)*0.80)\n# train data\nX_train=X_train_all[indices[:ind]] \ny_train=y_train_all[indices[:ind]]\n# validation data\nX_val=X_train_all[indices[-(len(indices)-ind):]] \ny_val=y_train_all[indices[-(len(indices)-ind):]]","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(X_train[0])\nX_train[0].shape","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"(28, 28)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_new=y_train.argmax(axis=1)\ny_train_new.shape\nprint(y_train_new.shape)\ny_train=y_train_new\n","execution_count":14,"outputs":[{"output_type":"stream","text":"(16048,)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Generator "},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_generator(img_shape, z_dim):\n\n    model = Sequential()\n\n    # Fully connected layer\n    model.add(Dense(128, input_dim=z_dim))\n\n    # Leaky ReLU activation\n    model.add(LeakyReLU(alpha=0.01))\n\n    # Output layer with tanh activation\n    model.add(Dense(28 * 28 * 1, activation='tanh'))\n\n    # Reshape the Generator output to image dimensions\n    model.add(Reshape(img_shape))\n\n    return model","execution_count":15,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Discriminator**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_discriminator(img_shape):\n\n    model = Sequential()\n\n    # Flatten the input image\n    model.add(Flatten(input_shape=img_shape))\n\n    # Fully connected layer\n    model.add(Dense(128))\n\n    # Leaky ReLU activation\n    model.add(LeakyReLU(alpha=0.01))\n\n    # Output layer with sigmoid activation\n    model.add(Dense(1, activation='sigmoid'))\n\n    return model","execution_count":16,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>The GAN Model   </h4>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_gan(generator, discriminator):\n\n    model = Sequential()\n\n    # Combined Generator -> Discriminator model\n    model.add(generator)\n    model.add(discriminator)\n\n    return model","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"z_dim=100\n\n# Build and compile the Discriminator\ndiscriminator = build_discriminator((28,28))\ndiscriminator.compile(loss='binary_crossentropy',\n                      optimizer=Adam(),\n                      metrics=['accuracy'])\n\n# Build the Generator\ngenerator = build_generator((28,28), z_dim)\n\n# Keep Discriminatorâ€™s parameters constant for Generator training\ndiscriminator.trainable = False\n\n# Build and compile GAN model with fixed Discriminator to train the Generator\ngan = build_gan(generator, discriminator)\ngan.compile(loss='binary_crossentropy', optimizer=Adam())","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"losses = []\naccuracies = []\niteration_checkpoints = []\n\n\ndef train(array,iterations, batch_size, sample_interval):\n\n    # Load the MNIST dataset\n#     (X_train, _), (_, _) = mnist.load_data()\n    X_train=array\n    # Rescale [0, 255] grayscale pixel values to [-1, 1]\n    X_train = X_train / 127.5 - 1.0\n    X_train = np.expand_dims(X_train, axis=3)\n\n    # Labels for real images: all ones\n    real = np.ones((batch_size, 1))\n\n    # Labels for fake images: all zeros\n    fake = np.zeros((batch_size, 1))\n\n    for iteration in range(iterations):\n\n        # -------------------------\n        #  Train the Discriminator\n        # -------------------------\n\n        # Get a random batch of real images\n        idx = np.random.randint(0, X_train.shape[0], batch_size)\n        imgs = X_train[idx]\n\n        # Generate a batch of fake images\n        z = np.random.normal(0, 1, (batch_size, 100))\n        gen_imgs = generator.predict(z)\n\n        # Train Discriminator\n        d_loss_real = discriminator.train_on_batch(imgs, real)\n        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n        d_loss, accuracy = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n        # ---------------------\n        #  Train the Generator\n        # ---------------------\n\n        # Generate a batch of fake images\n        z = np.random.normal(0, 1, (batch_size, 100))\n        gen_imgs = generator.predict(z)\n\n        # Train Generator\n        g_loss = gan.train_on_batch(z, real)\n\n        if (iteration + 1) % sample_interval == 0:\n\n            # Save losses and accuracies so they can be plotted after training\n            losses.append((d_loss, g_loss))\n            accuracies.append(100.0 * accuracy)\n            iteration_checkpoints.append(iteration + 1)\n\n            # Output training progress\n            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" %\n                  (iteration + 1, d_loss, 100.0 * accuracy, g_loss))\n\n            # Output a sample of generated image\n            sample_images(generator)","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndef sample_images(generator, image_grid_rows=4, image_grid_columns=4):\n\n    # Sample random noise\n    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n\n    # Generate images from random noise\n    gen_imgs = generator.predict(z)\n\n    # Rescale image pixel values to [0, 1]\n    gen_imgs = 0.5 * gen_imgs + 0.5\n\n    # Set image grid\n    fig, axs = plt.subplots(image_grid_rows,\n                            image_grid_columns,\n                            figsize=(4, 4),\n                            sharey=True,\n                            sharex=True)\n\n    cnt = 0\n    for i in range(image_grid_rows):\n        for j in range(image_grid_columns):\n            # Output a grid of images\n            axs[i, j].imshow(gen_imgs[cnt, :, :], cmap='gray')\n            axs[i, j].axis('off')\n            cnt += 1\n\n","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set hyperparameters\niterations = 20000\nbatch_size = 128\nsample_interval = 1000\n\n# Train the GAN for the specified number of iterations\ntrain(X_train,iterations, batch_size, sample_interval)","execution_count":null,"outputs":[{"output_type":"stream","text":"1000 [D loss: 1.345392, acc.: 14.84%] [G loss: 0.708077]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"losses = np.array(losses)\n\n# Plot training losses for Discriminator and Generator\nplt.figure(figsize=(15, 5))\nplt.plot(iteration_checkpoints, losses.T[0], label=\"Discriminator loss\")\nplt.plot(iteration_checkpoints, losses.T[1], label=\"Generator loss\")\n\nplt.xticks(iteration_checkpoints, rotation=90)\n\nplt.title(\"Training Loss\")\nplt.xlabel(\"Iteration\")\nplt.ylabel(\"Loss\")\nplt.legend()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}